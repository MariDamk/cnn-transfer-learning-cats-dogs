{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPGr5Jc6pXrO1lTM1K76w/p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariDamk/cnn-transfer-learning-cats-dogs/blob/main/CNN_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Cats vs Dogs Image Classification #\n",
        "\n",
        "##Changed to runtime type to T4 GPU instead of CPU, for faster results\n",
        "## Importing necessary libraries\n",
        "import os\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "## Defining temporary path and downloading the dataset with wget because for some reason with tf.keras.utils.get_file there was FileNotFound Error\n",
        "data_path = '/tmp/cats_and_dogs_filtered.zip'\n",
        "extract_path = '/tmp/'\n",
        "\n",
        "print(\"Downloading dataset... Chill...\")\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O {data_path}\n",
        "\n",
        "## Unziping the file\n",
        "with zipfile.ZipFile(data_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "## Directory paths\n",
        "base_dir = os.path.join(extract_path, 'cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "\n",
        "IMG_SIZE = 128\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "## Modified versions of the images are created to prevnt overfitting\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary' ## cat or dog\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "\n",
        "# Using MobileNetV2\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "## Training the model with just 15 epochs\n",
        "EPOCHS = 15\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n",
        "## plotting\n",
        "def plot_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    plt.figure(figsize=(16, 6))\n",
        "\n",
        "## Accuracy Plotting\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, acc, 'o-', label='Training Accuracy', color='darkorange', markersize=5)\n",
        "    plt.plot(epochs, val_acc, 'o-', label='Validation Accuracy', color='steelblue', markersize=5)\n",
        "    plt.title('Model Accuracy', fontsize=16)\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Accuracy', fontsize=12)\n",
        "    plt.legend(loc='lower right', fontsize=11)\n",
        "    plt.ylim([min(plt.ylim())-0.05, 1.05])\n",
        "\n",
        "## Loss Plotting\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, loss, 'o-', label='Training Loss', color='darkorange', markersize=5)\n",
        "    plt.plot(epochs, val_loss, 'o-', label='Validation Loss', color='steelblue', markersize=5)\n",
        "    plt.title('Model Loss', fontsize=16)\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Loss', fontsize=12)\n",
        "    plt.legend(loc='upper right', fontsize=11)\n",
        "    plt.ylim([0, max(plt.ylim())+0.1])\n",
        "\n",
        "    plt.suptitle('Enhanced Training & Validation History', fontsize=20, y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "L06FJSPqL1s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Eyo7FFoXsNl_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}